{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Science part of data involves forming and testing hypotheses about our data and the processes that generate it\n",
    "# Observations of random variables from known distributions, this allwos us to make statements about how likely\n",
    "# those assumptions are to hold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Flipping A Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is normal distribution with mean 500, st_dev , and n = 1000 flips:  500.0 15.811388300841896\n",
      "This is the rejected H0 falling outside of normal bounds 95% probability outside mu_0 and sigma_0:  (469.01026640487555, 530.9897335951244)\n",
      "Lower bound of 469, upper bound of 531. 5% chance of observing X outside this interval\n",
      "Type 2 Probability:  0.11345199870463285 Power:  0.8865480012953671\n",
      "This is the upper bound limit:  526.0073585242053\n",
      "This is the power:  0.9363794803307173\n"
     ]
    }
   ],
   "source": [
    "# Going to test normal distribution\n",
    "import math\n",
    "\n",
    "def normal_cdf(x, mu=0, sigma=1):\n",
    "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2\n",
    "\n",
    "def normal_approximation_to_binomial(n, p):\n",
    "    \"\"\"finds mu and sigma corresponding to a Binomial(n, p)\"\"\"\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma\n",
    "# We can use normal_cdf to figure out that its realized value lies within or outside a particular interval\n",
    "# the normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "# it's above the threshold if it's now below the threshold\n",
    "def normal_probability_above(lo, mu=0, sigma=1):\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)\n",
    "\n",
    "# Finding the nontail region or the symmetric interval around the mean that accounts for a certain level of likelihood\n",
    "# Interval centered at the mean containing 60% probability, then we find the cutoffs where the upper and lower tails\n",
    "# contain 20% of the probability (leaving 60%)\n",
    "\n",
    "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
    "    \"\"\"find approximate inverse using binary search\"\"\"\n",
    "    \n",
    "    # if not standard, compute standard and rescale\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, tolerance = tolerance)\n",
    "    \n",
    "    low_z = -10.0                                 # normal_cdf(-10) is (very close to) 0\n",
    "    hi_z = 10.0                                   # normal_cdf(10) is (very close to) 1\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2                # consider the midpoint\n",
    "        mid_p = normal_cdf(mid_z)                 # and the cdf's value there\n",
    "        if mid_p < p:\n",
    "            # midpoint is still to low, search above it\n",
    "            low_z = mid_z\n",
    "        elif mid_p > p:\n",
    "            # midpoint is still too high, search below it\n",
    "            hi_z = mid_z\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return mid_z\n",
    "\n",
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z wfor which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds\n",
    "    that contain the specified probability\"\"\"\n",
    "    # tail_p uses the opposite probability factor than the upper normal bounds\n",
    "    tail_probability = (1 - probability) / 2 # probability in percentage\n",
    "    \n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma) \n",
    "    \n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "print(\"This is normal distribution with mean 500, st_dev , and n = 1000 flips: \", mu_0, sigma_0) # Distributed approximately normally with mean 500 and st_dev 15.8 with coin flip n = 1000\n",
    "\n",
    "# H0 rejected if X falls outside the bounds given\n",
    "print(\"This is the rejected H0 falling outside of normal bounds 95% probability outside mu_0 and sigma_0: \",normal_two_sided_bounds(0.95, mu_0, sigma_0))\n",
    "print(\"Lower bound of 469, upper bound of 531. 5% chance of observing X outside this interval\")\n",
    "\n",
    "# Checking if p is NOT .5 but instead 0.55\n",
    "# Calculate the power of the test\n",
    "\n",
    "# 95% bounds based on assumption, p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "# actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "\n",
    "# a type 2 error means we fail to reject the null hypothesis\n",
    "# which will happen when X is still in our original interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "# Probability between regular (lo, hi) - irregular (0.55%)\n",
    "power = 1 - type_2_probability\n",
    "# This shows the coin slighly biased towards heads\n",
    "print(\"Type 2 Probability: \", type_2_probability, \"Power: \", power)\n",
    "# Significance Test to find the cutoff below which 95% of the probability lies\n",
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "print(\"This is the upper bound limit: \", hi)\n",
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print(\"This is the power: \", power)\n",
    "# More powerful test, since it no longer rejects H0 when X is below 469 and rejects between 526 and 531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 530 heads:  0.06207721579598857\n",
      "That would be 0.06 \n",
      "The extreme value count is :  0.06135\n",
      "This is 532 heads:  0.046345287837786575\n"
     ]
    }
   ],
   "source": [
    "# Instead of choosing bounds baed on some probability cutoff, we compute the probability that we would see a value\n",
    "# at least as extreme as the one we actually observed.\n",
    "\n",
    "# For our two sided test of whether the coin is fair\n",
    "import random\n",
    "\n",
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is what's greater than x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is what's less than x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)\n",
    "print(\"This is 530 heads: \", two_sided_p_value(529.5, mu_0, sigma_0))\n",
    "print(\"That would be %.2f \" % two_sided_p_value(529.5, mu_0, sigma_0))\n",
    "# 529.5 is a estimate of the probability of seeing 530 than normal_probability_between(530, 531, mu_0, sigma_0)\n",
    "# Convincing yourself\n",
    "extreme_value_count = 0\n",
    "for _ in range(100000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0             # count # of heads\n",
    "                   for _ in range(1000))                          # in 1000 flips\n",
    "    if num_heads >= 530 or num_heads <= 470:                      # and count how often\n",
    "        extreme_value_count += 1                                  # the # is 'extreme'\n",
    "    \n",
    "print(\"The extreme value count is : \", extreme_value_count / 100000)\n",
    "\n",
    "# The p value is greater than our 5% significance, we don't reject the null. \n",
    "# 532 heads, the p-value is this\n",
    "print(\"This is 532 heads: \", two_sided_p_value(531.5, mu_0, sigma_0))\n",
    "# This is smaller than 5% significance, which means we reject the null\n",
    "# Just a different way of approaching the stats.\n",
    "\n",
    "# Make sure data is roughly normally distributed beforeusing normal_probability above to compute p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is sigma with p_hat:  0.015791611697353755\n",
      "This is the confidence interval:  (0.4940490278129096, 0.5559509721870904)\n"
     ]
    }
   ],
   "source": [
    "# 3rd approach is to construct a confidence interval around the observed value of the parameter\n",
    "# math.sqrt(p * (1 - p) / 1000)\n",
    "# Don't know p, so we use our estimate\n",
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "print(\"This is sigma with p_hat: \", sigma)\n",
    "# The following interval contains the true parameter p\n",
    "normal_two_sided_bounds(0.95, mu, sigma)\n",
    "print(\"This is the confidence interval: \", normal_two_sided_bounds(0.95, mu, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of rejections:  46\n"
     ]
    }
   ],
   "source": [
    "# Procedure that erroneously rejects the null hypothesis only 5% of the time will - by definition - 5% of the time\n",
    "# erroneously reject the null hypothesis\n",
    "\n",
    "def run_experiment():\n",
    "    \"\"\"flip a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    return [random.random() < 0.5 for _ in range(1000)]\n",
    "def reject_fairness(experiment):\n",
    "    \"\"\"using the 5% significance levels\"\"\"\n",
    "    num_heads = len([flip for flip in experiment if flip]) #\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment\n",
    "                     for experiment in experiments\n",
    "                     if reject_fairness(experiment)])\n",
    "print(\"This is the number of rejections: \", num_rejections)\n",
    "# Determine your hypothesis before looking at your data, clean data with hypothesis in mind\n",
    "# p values are not substitutes for common sense\n",
    "# Alternative approach is Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Running an A/B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 200 clicks out of 1000 and 180 clicks out of 1000:  -1.1403464899034472\n",
      "Two sided p value of z:  0.254141976542236\n",
      "New z:  -2.948839123097944 New two sided p value:  0.003189699706216853\n"
     ]
    }
   ],
   "source": [
    "# Here is why you would use statistical inference\n",
    "# 990 / 1000 visitors click the Ad-A while 10 / 1000 click the Ad-B\n",
    "# This is a pretty good difference but most statistics won't be this way.\n",
    "\n",
    "# N(A) people see Ad A and n(A) click on it\n",
    "# p(A) is the probability that someone clicks ad A\n",
    "\n",
    "def estimated_parameters(N, n):\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1 - p) / N)\n",
    "    return p, sigma\n",
    "# This math only really works out if you know the standard deviations\n",
    "# For large datasets it's close enough that it doesn't make much of a difference\n",
    "\n",
    "# Testing the null hypothesis that p(A) and p(B) are the same (0) using the statistic\n",
    "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)\n",
    "# This should be a standard normal\n",
    "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
    "print(\"This is 200 clicks out of 1000 and 180 clicks out of 1000: \", z)\n",
    "\n",
    "# The probability of seeing such a large difference if the means were actually equal\n",
    "print(\"Two sided p value of z: \", two_sided_p_value(z))\n",
    "# 0.254 Large enough that you can't conclude there's much of a difference\n",
    "z = a_b_test_statistic(1000, 200, 1000, 150)\n",
    "two_sided_p_value(z)\n",
    "print(\"New z: \", z, \"New two sided p value: \", two_sided_p_value(z))\n",
    "# 0.003 probability you'd see such a large difference if the ads were equally effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedures before have involved making probability statements about our tests and hypothesis.\n",
    "# An alternative approach to inference involves trating the unknown parameters themselves as random vars.\n",
    "# Rather than making judgements about the tests, make probability judgements about the parameters themselves\n",
    "\n",
    "# Use a prior from the beta distribution which puts all its probabilities between 0 and 1\n",
    "# math.gamma = (1 - n)!\n",
    "def B(alpha, beta):\n",
    "    \"\"\"a normalizing constant so that the total probability is 1\"\"\"\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x, alpha, beta):\n",
    "    if x <= 0 or x >= 1:\n",
    "        return 0\n",
    "    return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta)\n",
    "# Distribution is centers its weight at alpha / (alpha + beta)\n",
    "# The larger alpha and beta are, the \"higher\" the distribution is\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
